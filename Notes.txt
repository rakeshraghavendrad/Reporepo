from deepeval.metrics import FaithfulnessMetric
from deepeval.test_case import LLMTestCase

# âœ… Subclass FaithfulnessMetric to force strict JSON format
class StrictFaithfulnessMetric(FaithfulnessMetric):
    def _construct_prompt(self, context, output):
        return f"""
Evaluate how faithful the given output is to the provided context.

Return ONLY the result in the following exact JSON format:
{{
  "score": float (between 0 and 1),
  "reason": string
}}

Context:
"{context}"

Output:
"{output}"
"""

# âœ… Inputs
actual_output = "We offer a 30-day full refund at no extra cost."
retrieval_context = ["All customers are eligible for a 30 day full refund at no extra cost."]

# âœ… Create the metric using Gemini or GPT-4
metric = StrictFaithfulnessMetric(
    threshold=0.7,
    model="gemini-2.0-flash-001",  # OR "gpt-4"
    include_reason=True
)

# âœ… Define your test case
test_case = LLMTestCase(
    input="What if these shoes don't fit?",
    actual_output=actual_output,
    retrieval_context=retrieval_context
)

# âœ… Run and print the score and reason
metric.measure(test_case)
print("âœ… Score:", metric.score)
print("ðŸ’¬ Reason:", metric.reason)
