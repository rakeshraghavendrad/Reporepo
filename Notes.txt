Consistency level:

Outputs across runs share ~66% overlap in words (ROUGE-1).

Outputs share ~61% overlap in sentence structure/phrasing (ROUGE-L).

Balance between runs:

Precision ≈ Recall in both metrics → no one run is “longer” or “shorter” than others; differences are balanced.

Stability vs. variability:

The system is reasonably stable (common vocabulary is repeated across runs).

But there’s healthy variation in phrasing and ordering, which explains the slightly lower ROUGE-L.

Takeaway:

Runs are not identical but broadly consistent, showing the model is stable while still generating diverse outputs.
