import json
import re
from deep_eval.metrics.base import BaseMetric
from deep_eval.test_case import LLMTestCase


class CustomContextualPrecisionMetric(BaseMetric):
    """
    Custom Contextual Precision Metric that outputs score (0-1) and reason,
    instead of DeepEval's default verdict structure.
    """

    def __init__(self, model, threshold: float = 0.7, include_reason: bool = True):
        self.model = model
        self.threshold = threshold
        self.include_reason = include_reason

        # Prompt ensures consistent JSON output
        self.prompt_template = """
Evaluate how contextually precise the 'actual output' is compared to the 'expected output' 
using the given retrieval context.

Return strictly in JSON format:
{
  "score": <float between 0 and 1>,
  "reason": "<concise explanation>"
}
Score should reflect contextual precision (1 = fully precise, 0 = not precise).
"""

    def measure(self, test_case: LLMTestCase):
        # Construct prompt
        prompt = f"""
{self.prompt_template}

Expected Output:
{test_case.expected_output}

Actual Output:
{test_case.actual_output}

Context:
{test_case.retrieval_context}
"""

        # Call LLM
        response = self.model.generate(prompt)

        # Clean JSON
        cleaned = re.sub(r"^```(?:json)?\s*|\s*```$", "", response.strip())
        try:
            parsed = json.loads(cleaned)
            self.score = parsed.get("score")
            self.reason = parsed.get("reason") if self.include_reason else None
        except Exception:
            self.score = None
            self.reason = response  # fallback raw

        return json.dumps({"score": self.score, "reason": self.reason})






ContextualPrecisionMetric_metric = CustomContextualPrecisionMetric(
    model=llm_no_ssl,
    threshold=0.7,
    include_reason=True
)




def apply_ContextualPrecisionMetric(row):
    test_case = LLMTestCase(
        input="Evaluate contextual precision and return score + reason",
        actual_output=row["NewSummary"],
        expected_output=row["Agentnotes"],
        retrieval_context=[row["Agentcontext"]]
    )

    result = ContextualPrecisionMetric_metric.measure(test_case)

    # Parse result (already JSON)
    parsed = json.loads(result)
    return pd.Series({
        "ContextualPrecisionMetric_score": parsed.get("score"),
        "ContextualPrecisionMetric_reason": parsed.get("reason")
    })
