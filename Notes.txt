

import re
import pandas as pd

# Function to remove ANSI escape characters
def remove_ansi_escape(text):
    ansi_escape = re.compile(r'\x1b\[[0-9;]*m')
    return ansi_escape.sub('', text)

# Keywords to track
keywords = [
    "Added merchant file URL to claim data",
    "Prompt on compelling photographic or email evidence returned",
    "Prompt on compelling merchandise pickup",
    "Prompt on compelling delivery",
    "AVS response not found, returning non-compelling evidence",
    "Prompted profile check",
    "Prompt checking for credits or refunds finished",
    "Generated summary of compelling evidence",
    "Received response from Tachyon"
]

# Read the file
input_file = "your_log_file_path_here.log"  # <-- UPDATE THIS PATH
with open(input_file, "r", encoding="utf-8") as infile:
    lines = infile.readlines()

# Initialization
records = []
current_claim_data = "Not found"
input_buffer = ""
capturing_input = False

# Process lines
for raw_line in lines:
    line = remove_ansi_escape(raw_line.strip())

    # Step 1: Update claim_data if PDF found
    claim_match = re.search(r'claim data.*?([^\\/:\*\?"<>\|\r\n]+\.pdf)', line)
    if claim_match:
        current_claim_data = claim_match.group(1)

    # Step 2: Handle input= blocks
    if "input=" in line:
        input_value = line.split("input=", 1)[1].strip()

        # Case: Single-line input like a PDF
        if re.match(r".*\.pdf", input_value, re.IGNORECASE):
            input_buffer = input_value
            capturing_input = False
        else:
            # Start buffering multiline input
            input_buffer = input_value
            capturing_input = True
        continue

    elif capturing_input:
        input_buffer += " " + line
        if "document." in line or line.endswith("}") or "}}" in line:
            capturing_input = False  # End of multiline block

    # Step 3: Match keywords and extract associated fields
    for keyword in keywords:
        if keyword in line:
            input_value_final = input_buffer.strip() if input_buffer else "Not found"

            evidence_match = re.search(r'evidence(?:=|\s*:\s*")([^"]+)', line)
            summary_match = re.search(r'summary(?:=|\s*:\s*")([^"]+)', line)
            is_compelling_match = re.search(r'is_compelling=(True|False)', line)
            generated_text_match = re.search(r'generated_text(?:=|\s*:\s*")([^"]+)', line)
            cardholder_profile_match = re.search(r'cardholder_profile=\{(.*?)\}', line)

            records.append({
                "claim_data": current_claim_data,
                "keyword": keyword,
                "input": input_value_final,
                "evidence": evidence_match.group(1) if evidence_match else "Not found",
                "summary": summary_match.group(1) if summary_match else "Not found",
                "is_compelling": is_compelling_match.group(1) if is_compelling_match else "Not found",
                "generated_text": generated_text_match.group(1) if generated_text_match else "Not found",
                "cardholder_profile": cardholder_profile_match.group(1) if cardholder_profile_match else "Not found"
            })

            input_buffer = ""  # reset after a successful match
            break  # skip checking other keywords for this line

# Convert to DataFrame and display
df = pd.DataFrame(records)
df



input_match = re.search(r'input=(\{.*?\}|\S+)', line, re.DOTALL)






# Initialize
records = []
current_claim_data = "Not found"  # Holds the last seen claim_data PDF filename

# Loop through all lines
for raw_line in lines:
    line = remove_ansi_escape(raw_line.strip())  # Clean line

    # Update current claim_data if new one is found
    claim_match = re.search(r'claim data.*?([^\\/:\*\?"<>\|\r\n]+\.pdf)', line)
    if claim_match:
        current_claim_data = claim_match.group(1)

    # Check for any keyword match
    for keyword in keywords:
        if keyword in line:
            # Extract additional fields using regex
            input_match = re.search(r'input_=([\S+\.pdf]+)', line)
            evidence_match = re.search(r'evidence(?:=|\s*:\s*")([^"]+)', line)
            summary_match = re.search(r'summary(?:=|\s*:\s*")([^"]+)', line)
            is_compelling_match = re.search(r'is_compelling=(True|False)', line)
            generated_text_match = re.search(r'generated_text(?:=|\s*:\s*")([^"]+)', line)
            cardholder_profile_match = re.search(r'cardholder_profile=\{(.*?)\}', line)

            # Append data to records list
            records.append({
                "claim_data": current_claim_data,
                "keyword": keyword,
                "input": input_match.group(1) if input_match else "Not found",
                "evidence": evidence_match.group(1) if evidence_match else "Not found",
                "summary": summary_match.group(1) if summary_match else "Not found",
                "is_compelling": is_compelling_match.group(1) if is_compelling_match else "Not found",
                "generated_text": generated_text_match.group(1) if generated_text_match else "Not found",
                "cardholder_profile": cardholder_profile_match.group(1) if cardholder_profile_match else "Not found"
            })
            break  # Stop checking other keywords once matched

# Convert to DataFrame
df = pd.DataFrame(records)

# Display or export
# df.to_csv("extracted_case_data.csv", index=False)
df
