from sentence_transformers import SentenceTransformer
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.metrics import SemanticSimilarity
from ragas.types import SingleTurnSample
from langchain.embeddings import FakeEmbeddings  # this won't be used, just for reference

# Initialize SentenceTransformer model directly
model = SentenceTransformer('all-MiniLM-L6-v2')  # local model, no HF access needed

# Create a Langchain-compatible wrapper
class CustomEmbeddingWrapper:
    def embed_documents(self, texts):
        return model.encode(texts).tolist()

    def embed_query(self, text):
        return model.encode([text])[0].tolist()

# Wrap the custom embedding in Langchain/RAGAS-compatible wrapper
evaluator_embeddings = LangchainEmbeddingsWrapper(CustomEmbeddingWrapper())

# Define your sample
sample = SingleTurnSample(
    response="The Eiffel Tower is located in Paris.",
    reference="The Eiffel Tower is located in Paris. It has a height of 1000ft."
)

# Score with SemanticSimilarity
scorer = SemanticSimilarity(embeddings=evaluator_embeddings)
score = await scorer.single_turn_ascore(sample)
print(score)
